# -*- coding: utf-8 -*-
"""Tech challenge Data Scientist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L6V1qo1VIZbofDwuBnumu5c_VZF1kEww

# Import
"""

import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import lightgbm as lgb
from sklearn.metrics import r2_score, accuracy_score, mean_absolute_error, mean_squared_error

df = pd.read_csv("https://raw.githubusercontent.com/murpi/wilddata/master/test/history.csv", sep = ',')
df

"""# Analyse descriptive exploratoire

## Mise au format des colonnes
"""

df.info()

# Convertion dela colonne date au format date
df['DATE'] = pd.to_datetime(df['DATE'])

# Ajout de la colonne mois
df['MONTH'] = df['DATE'].dt.month

# Ajout de la colonne jour de la semaine
df["DAY"] = pd.Categorical(df['DATE'].dt.day_name(), 
                           categories=["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"], 
                           ordered=True)

# Répartition des items
df['ITEM'].value_counts()

"""## Graphiques sur les ventes globales"""

# Graphique des ventes de A et B en fonction des mois
plt.figure(figsize = (15, 10))
sns.lineplot(x = df.MONTH, y = df.SALES, hue = df.ITEM, palette = ['LightPink', 'Indigo']);

# Graphique sur les ventes
fig, axes = plt.subplots(1, 3, figsize=(20, 5))
df.groupby("DAY")['SALES'].sum().plot(kind='bar', ax=axes[0], color = 'Lightblue')
df.groupby("MONTH")['SALES'].sum().plot(kind='bar', ax=axes[1], color = 'Lightblue')
df.groupby("DATE")['SALES'].sum().plot(kind='line', ax=axes[2], color = 'Lightblue');

"""## Graphiques sur les ventes de A"""

fig, axes = plt.subplots(1, 3, figsize=(20, 5))
df[df['ITEM'] == 'A'].groupby("DAY")['SALES'].sum().plot(kind='bar', ax=axes[0], color = "Lightpink")
df[df['ITEM'] == 'A'].groupby("MONTH")['SALES'].sum().plot(kind='bar', ax=axes[1], color = "Lightpink")
df[df['ITEM'] == 'A'].groupby("DATE")['SALES'].sum().plot(kind='line', ax=axes[2], color = "Lightpink");

# Détermination des jours où il n'y a pas de vente de A
dfA = df.loc[df['ITEM'] == 'A']
date_manquanteA = pd.date_range(min(df['DATE']),max(df['DATE'])).difference(dfA['DATE'])
date_manquanteA = pd.DataFrame(date_manquanteA, columns = ['DATE'])
date_manquanteA['DAY'] = pd.Categorical(date_manquanteA['DATE'].dt.day_name(), 
                           categories=["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"], 
                           ordered=True)
date_manquanteA

# Répartition des jours où pas de vente
date_manquanteA.groupby("DAY")['DATE'].count().plot(kind='bar', color = "Lightpink");

"""## Graphiques sur les ventes de B"""

fig, axes = plt.subplots(1, 3, figsize=(20, 5))
df[df['ITEM'] == 'B'].groupby("DAY")['SALES'].sum().plot(kind='bar', ax=axes[0], color = "Indigo")
df[df['ITEM'] == 'B'].groupby("MONTH")['SALES'].sum().plot(kind='bar', ax=axes[1], color = "Indigo")
df[df['ITEM'] == 'B'].groupby("DATE")['SALES'].sum().plot(kind='line', ax=axes[2], color = "Indigo");

# Détermination des jours
dfB = df.loc[df['ITEM'] == 'B']
date_manquanteB = pd.date_range(min(df['DATE']),max(df['DATE'])).difference(dfB['DATE'])
date_manquanteB = pd.DataFrame(date_manquanteB, columns = ['DATE'])
date_manquanteB['DAY'] = pd.Categorical(date_manquanteB['DATE'].dt.day_name(), 
                           categories=["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"], 
                           ordered=True)
date_manquanteB

# Répartition des jours où pas de vente afin de vérifier si un jour se démarque
date_manquanteB.groupby("DAY")['DATE'].count().plot(kind='bar', color = "Indigo");

"""# Trouver la boutique correspondante

## Préparation des données dans df
"""

# Création de 2 colonnes distinctes pour les ventes de A et de B
dfA = df.loc[df.ITEM == 'A', ['DATE','MONTH','SALES']].rename(columns= {'SALES' : 'SALES_A'})
dfB = df.loc[df.ITEM == 'B', ['DATE','SALES']].rename(columns= {'SALES' : 'SALES_B'})
df_sale = pd.merge(dfA, dfB, how = 'inner', left_on = 'DATE', right_on = 'DATE')
df_sale

"""## Fonction de chargement des fichiers CSV"""

# Fonction de chargement des fichiers CSV
# et retourne les dataframe des météos des villes

def chargement (ville) :
    # Chargement du fichier csv
    df_ville = pd.read_csv('https://raw.githubusercontent.com/murpi/wilddata/master/test/'+ville+'2019.csv',sep = ',', header = 3)

    # Convertion de la colone DATE en type datetime
    df_ville['DATE'] = pd.to_datetime(df_ville['DATE'])

    # Jointure entre les ventes (df_sale) et la météo des villes (df_ville)
    df_ville = pd.merge(df_sale, df_ville, how  = 'inner', left_on = 'DATE', right_on  = 'DATE')

    return df_ville

# Affectation des fichiers transformés en dataframe dans des variables (df_bordeaux, df_lille...)
ville = ['bordeaux', 'lille', 'lyon', 'marseille']

for i in ville :
    globals()['df_%s' % i] = chargement(i)

"""## Comportement des ventes de A et B en fonction de la météo (OPINION)"""

# Fonction qui prend en entrée un nom de ville et qui retourne 2 graphiques
# pour les ventes de A et B en fonction de l'opinion

def vente_opinion(ville) :

    fig, axes = plt.subplots(1,2, figsize = (20,10))

    plt.title('Ventes de A')
    sns.scatterplot(ax = axes[0], x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville]['SALES_A'], hue = globals()['df_%s' % ville]['OPINION'])
    sns.lineplot(ax = axes[0], x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville]['SALES_A'], color = 'LightPink')

    plt.title('Ventes de B')
    sns.scatterplot(ax = axes[1], x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville]['SALES_B'], hue = globals()['df_%s' % ville]['OPINION'])
    sns.lineplot(ax = axes[1], x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville]['SALES_B'], color = 'Indigo')

    plt.show()

    return

# Edition des graphiques pour chaque ville

for i in ville :

    print(i)
    vente_opinion(i)

"""# Explication de l'impact de la météo

## Création de fonctions
"""

# Fonction qui prend en entrée une ville et qui retourne une heatmap

def heatmap(ville) :
    
    plt.figure(figsize = (8,5))
    plt.title('Ville de '+ville)
    sns.heatmap(globals()['df_%s' % ville].corr(), cmap = 'vlag', center = 0)
    
    return

# Fonction qui prend en entrée le nom d'une ville 
# et qui retourne un graphique des colonnes corrélées aux ventes

def graphique(ville) :
    
    # Détermination de la colonne la plus corrélée avec SALES_A et de celle avec SALES_B
    corr_saleA = globals()['df_%s' % ville].corr().drop(index = ['SALES_A', 'SALES_B'])['SALES_A'].idxmax()
    corr_saleB = globals()['df_%s' % ville].corr().drop(index = ['SALES_A', 'SALES_B'])['SALES_B'].idxmax()
    
    # Représentation graphique des variables corrélées
    plt.figure(figsize = (10,7))
    plt.title('Ville de '+ville)
    '''return (sns.lineplot(x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville][corr_saleB], color = 'Indigo'),
            sns.lineplot(x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville][corr_saleA], color = 'LightPink'),
            plt.legend(loc='upper left', labels = ('B : '+corr_saleB, 'A : '+corr_saleA)))'''
    sns.scatterplot(x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville][corr_saleB], color = 'Indigo'),
    sns.scatterplot(x = globals()['df_%s' % ville]['DATE'], y = globals()['df_%s' % ville][corr_saleA], color = 'LightPink'),
    plt.legend(loc='upper left', labels = ('B : '+corr_saleB, 'A : '+corr_saleA))

    return

"""## Edition des graphiques expliquant les corrélations entre chaque dimension pour chaque ville"""

# Corrélation des dimensions pour Bordeaux
df_bordeaux.corr()

# Corrélation des dimensions pour Lille
df_lille.corr()

# Corrélation des dimensions pour Lyon
df_lyon.corr()

# Corrélation des dimensions pour Marseille
df_marseille.corr()

# Affichage des corrélations entre toutes les dimensions
for i in ville :

    # Affichage des heatmap
    heatmap(i)

# Affichage des dimensions les plus corrélées avec les ventes
for i in ville :

    # Affichage des graphiques
    graphique(i)

"""# Prévision de ventes

## Import du fichier des ventes à prédire
"""

# Chargement du fichier de la météo d'une semaine
df_meteo = pd.read_csv('https://raw.githubusercontent.com/murpi/wilddata/master/test/forecast.csv', sep = ',')
df_meteo['DATE'] = pd.to_datetime(df_meteo['DATE'])
df_meteo['MONTH'] = df_meteo.DATE.dt.month
df_meteo

df_meteo.info()

"""## Prévision des ventes avec la régression linéaire

### Ventes de A
"""

# Définition de X et de y
X = df_bordeaux[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']]
y = df_bordeaux.SALES_A

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)

# Entrainement du modèle
linReg = LinearRegression().fit(X_train, y_train)

# Evaluation du modèle
y_pred_train = linReg.predict(X_train)
y_pred_test = linReg.predict(X_test)

print("MAE train :", round(mean_absolute_error(y_train, y_pred_train)))
print("MAE test :", round(mean_absolute_error(y_test, y_pred_test)))
print("RMSE train :", round(mean_squared_error(y_train, y_pred_train)** 0.5))
print("RMSE test :", round(mean_squared_error(y_test, y_pred_test)** 0.5))
print("r2_train:", round(r2_score(y_train, y_pred_train), 3))
print("r2_test:", round(r2_score(y_test, y_pred_test), 3))

# Prédiction
df_meteo['SALES_A'] = linReg.predict(df_meteo[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']])
df_meteo['SALES_A'] = round(df_meteo['SALES_A'])
df_meteo

"""### Ventes de B"""

# Définition de X et de y
X = df_bordeaux[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']]
y = df_bordeaux.SALES_B

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)

# Entrainement du modèle
linReg = LinearRegression().fit(X_train, y_train)

# Evaluation du modèle
y_pred_train = linReg.predict(X_train)
y_pred_test = linReg.predict(X_test)

print("MAE train :", round(mean_absolute_error(y_train, y_pred_train)))
print("MAE test :", round(mean_absolute_error(y_test, y_pred_test)))
print("RMSE train :", round(mean_squared_error(y_train, y_pred_train)** 0.5))
print("RMSE test :", round(mean_squared_error(y_test, y_pred_test)** 0.5))
print("r2_train:", round(r2_score(y_train, y_pred_train), 3))
print("r2_test:", round(r2_score(y_test, y_pred_test), 3))

# Prédiction
df_meteo['SALES_B'] = linReg.predict(df_meteo[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']])
df_meteo['SALES_B'] = round(df_meteo['SALES_B'])
df_meteo

"""## Prévision des ventes avec Light GBM

### Ventes de A
"""

# Définition de X et de y
X = df_bordeaux[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']]
y = df_bordeaux.SALES_A

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)

# definition des paramètes 
params = {
    'task': 'train', 
    'boosting': 'gbdt',
    'objective': 'regression',
    'num_leaves': 10,
    'learnnig_rage': 0.05,
    'metric': {'l2','l1'},
    'verbose': -1
}

# Chargement des données pour le light GBM
lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)

# Entrainement du modèle
model = lgb.train(params,
                 train_set=lgb_train,
                 valid_sets=lgb_eval,
                 early_stopping_rounds=30)

# prediction
y_pred_test = model.predict(X_test)
y_pred_train = model.predict(X_train)

# score
print("MAE train :", round(mean_absolute_error(y_train, y_pred_train)))
print("MAE test :", round(mean_absolute_error(y_test, y_pred_test)))
print("RMSE train : ", round(mean_squared_error(y_train, y_pred_train)**0.5))
print("RMSE test : ", round(mean_squared_error(y_test, y_pred_test)**0.5))

# Visualisation des données prédites et réelles
ax = range(len(y_test))
plt.figure(figsize=(12, 6))
plt.plot(ax, y_test, label="Données réelles")
plt.plot(ax, y_pred_test, label="Données prédites")
plt.title("Comparaison des données réelles et prédites")
plt.xlabel('X')
plt.ylabel('Prix')
plt.legend(loc='best',fancybox=True, shadow=True)
plt.grid(True)
plt.show()

# feature importance
lgb.plot_importance(model, height=.5);

# Prédiction sur df_meteo
df_meteo['SALES_A'] = model.predict(df_meteo[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']])
df_meteo['SALES_A'] = round(df_meteo['SALES_A'])
df_meteo

"""### Ventes de B"""

# Définition de X et de y
X = df_bordeaux[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']]
y = df_bordeaux.SALES_B

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)

# definition des paramètes 
params = {
    'task': 'train', 
    'boosting': 'gbdt',
    'objective': 'regression',
    'num_leaves': 10,
    'learnnig_rage': 0.05,
    'metric': {'l2','l1'},
    'verbose': -1
}

# Chargement des données pour le light GBM
lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)

# Entrainement du modèle
model = lgb.train(params,
                 train_set=lgb_train,
                 valid_sets=lgb_eval,
                 early_stopping_rounds=30)

# prediction
y_pred_test = model.predict(X_test)
y_pred_train = model.predict(X_train)

# score
print("MAE train :", round(mean_absolute_error(y_train, y_pred_train)))
print("MAE test :", round(mean_absolute_error(y_test, y_pred_test)))
print("RMSE train : ", round(mean_squared_error(y_train, y_pred_train)**0.5))
print("RMSE test : ", round(mean_squared_error(y_test, y_pred_test)**0.5))

# Visualisation des données prédites et réelles
ax = range(len(y_test))
plt.figure(figsize=(12, 6))
plt.plot(ax, y_test, label="Données réelles")
plt.plot(ax, y_pred_test, label="Données prédites")
plt.title("Comparaison des données réelles et prédites")
plt.xlabel('X')
plt.ylabel('Prix')
plt.legend(loc='best',fancybox=True, shadow=True)
plt.grid(True)
plt.show()

# feature importance
lgb.plot_importance(model, height=.5);

# Prédiction sur df_meteo
df_meteo['SALES_B'] = model.predict(df_meteo[['MAX_TEMPERATURE_C', 'MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'PRECIP_TOTAL_DAY_MM',
                 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM', 'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'MONTH']])
df_meteo['SALES_B'] = round(df_meteo['SALES_B'])
df_meteo